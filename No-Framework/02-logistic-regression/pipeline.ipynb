{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e12a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 454,902 samples, 30 features\n",
      "Test: 56,962 samples\n",
      "Class balance - Train: 50.0% fraud\n",
      "Class balance - Test: 0.2% fraud\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Logistic Regression - No Framework Implementation\n",
    "Built from scratch using only NumPy.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Self created utilities\n",
    "from utils.metrics import accuracy, precision, recall, f1_score, auc_score\n",
    "from utils.performance import track_performance\n",
    "from utils.visualization import (\n",
    "    plot_cost_curve,\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc_curve,\n",
    "    plot_feature_importance\n",
    ")\n",
    "\n",
    "# Load preprocessed data (already scaled, SMOTE applied, 50/50 balanced)\n",
    "X_train = np.load('../../data/processed/logistic_regression/X_train.npy')\n",
    "X_test = np.load('../../data/processed/logistic_regression/X_test.npy')\n",
    "y_train = np.load('../../data/processed/logistic_regression/y_train.npy')\n",
    "y_test = np.load('../../data/processed/logistic_regression/y_test.npy')\n",
    "\n",
    "# Load metadata for feature names\n",
    "with open('../../data/processed/logistic_regression/preprocessing_info.json') as f:\n",
    "    meta = json.load(f)\n",
    "feature_names = meta['feature_names']\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test: {X_test.shape[0]:,} samples\")\n",
    "print(f\"Class balance - Train: {np.mean(y_train):.1%} fraud\")\n",
    "print(f\"Class balance - Test: {np.mean(y_test):.1%} fraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d535c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core functions for logistic regression\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Sigmoid activation function.\n",
    "    Maps any real number to (0, 1) range - perfect for probability output.\n",
    "    \"\"\"\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Binary Cross-Entropy Loss (Log Loss).\n",
    "    Measures how well predicted probabilities match actual labels.\n",
    "\n",
    "    Formula: -[y*log(p) + (1-y)*log(1-p)]\n",
    "    - When y=1: loss = -log(p)     → penalizes low probability for fraud\n",
    "    - When y=0: loss = -log(1-p)   → penalizes high probability for legit\n",
    "    \"\"\"\n",
    "    # Clip predictions to avoid log(0)\n",
    "    eps = 1e-15\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31956770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  100 | Cost: 0.144255\n",
      "Iteration  200 | Cost: 0.100753\n",
      "Iteration  300 | Cost: 0.083974\n",
      "Iteration  400 | Cost: 0.075091\n",
      "Iteration  500 | Cost: 0.069554\n",
      "Iteration  600 | Cost: 0.065747\n",
      "Iteration  700 | Cost: 0.062953\n",
      "Iteration  800 | Cost: 0.060806\n",
      "Iteration  900 | Cost: 0.059100\n",
      "Iteration 1000 | Cost: 0.057708\n",
      "\n",
      "Training complete!\n",
      "Time: 18.34 sec | Memory: 27.87 MB\n"
     ]
    }
   ],
   "source": [
    "# Training: Gradient Descent\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "n_iterations = 1000\n",
    "\n",
    "# Initalize weights and bias to zero\n",
    "n_features = X_train.shape[1]\n",
    "weights = np.zeros(n_features)\n",
    "bias = 0.0\n",
    "\n",
    "# Track cost history for visualization\n",
    "cost_history = []\n",
    "\n",
    "# Training loop with performance tracking\n",
    "with track_performance() as perf:\n",
    "    for i in range(n_iterations):\n",
    "        # Forward pass: compute predictions\n",
    "        z = np.dot(X_train, weights) + bias     # Linear combination\n",
    "        y_pred = sigmoid(z)                     # Apply sigmoid for probabilities\n",
    "\n",
    "        # Compute cost (for monitoring, not used in gradients)\n",
    "        cost = binary_cross_entropy(y_train, y_pred)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Compute gradients (derivative of cost w.r.t. weights and bias)\n",
    "        # These come from calculus - the chain rule applied to BCE + sigmoid\n",
    "        error = y_pred - y_train                        # (predictions - actual)\n",
    "        dw = np.dot(X_train.T, error) / len(y_train)    # Gradient for weights\n",
    "        db = np.mean(error)                             # Gradient for bias\n",
    "\n",
    "        # Update parameters (move opposite to gradient direction)\n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "\n",
    "        # Print progress every 100 iterations\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Iteration {i+1:4d} | Cost: {cost:.6f}\")\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Time: {perf['time']:.2f} sec | Memory: {perf['memory']:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eae184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Portfolio (.venv)",
   "language": "python",
   "name": "ml-portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
