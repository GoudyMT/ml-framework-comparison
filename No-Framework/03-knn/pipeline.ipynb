{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb4fbdf",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) - No-Framework Implementation\n",
    "\n",
    "Multi-class classification on the **Covertype (Forest Cover Type)** dataset using pure NumPy.\n",
    "\n",
    "**Dataset**: 581,012 samples, 54 features, 7 forest cover types  \n",
    "**Task**: Predict forest cover type from cartographic variables  \n",
    "**Key Concept**: KNN is a \"lazy learner\" - no training phase, expensive at prediction time\n",
    "\n",
    "## What We'll Build From Scratch\n",
    "- **Euclidean/Manhattan distance** calculation (vectorized)\n",
    "- **K-nearest neighbor search** using argsort\n",
    "- **Majority voting** for multi-class prediction\n",
    "- **Batched prediction** to handle 464K training samples without OOM\n",
    "- **Distance-weighted voting** (optional advanced feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eea6e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append('../..')\n",
    "from utils.data_loader import load_processed_data\n",
    "from utils.metrics import accuracy, macro_f1_score, confusion_matrix_multiclass\n",
    "from utils.visualization import (\n",
    "    plot_confusion_matrix_multiclass,\n",
    "    plot_validation_curve,\n",
    "    plot_per_class_f1\n",
    ")\n",
    "from utils.performance import track_performance\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1698d25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 464,809 samples, 54 features\n",
      "Test set: 116,203 samples\n",
      "Classes (7): ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n"
     ]
    }
   ],
   "source": [
    "# Load Preprocessed data\n",
    "\"\"\"\n",
    "Data was preprocessed in data-preperation/preprocess_knn.py\n",
    "    - 80/20 split\n",
    "    - StandardScaler applied (fit on train only)\n",
    "    - All 4 frameworks load identical data for fair comparison\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_test, y_train, y_test, metadata = load_processed_data('knn')\n",
    "\n",
    "# Extract metadata for reference\n",
    "class_names = metadata['class_names']\n",
    "n_classes = metadata['n_classes']\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"Classes ({n_classes}): {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da68f0b",
   "metadata": {},
   "source": [
    "## Manhattan Distance Function\n",
    "\n",
    "- Scikit-Learn found that **Manhattan distance** (L1) outperforms Euclidean (L2) for this dataset.\n",
    "- We'll implement Manhattan distance from scratch.\n",
    "\n",
    "**Manhattan Distance Formula.**\n",
    "$$d(x, y) = \\sum_{i=1}^{n} |x_i - y_i|$$\n",
    "\n",
    "Sum of absolute differences across all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b9a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix shape: (3, 5)\n",
      "Sample distances from test[0] to first 5 train samples:\n",
      "[28.32663799 16.68044501 35.29420896 31.71431377 16.84263946]\n"
     ]
    }
   ],
   "source": [
    "# Manhattan Distance (Vectorized)\n",
    "\n",
    "def manhattan_distance_batch(X_batch, X_train):\n",
    "    \"\"\"\n",
    "    Compute Manhattan (L1) distance from each sample in X_batch\n",
    "    to all samples in X_train.\n",
    "\n",
    "    Vectorized using broadcasting for efficiency:\n",
    "        - X_batch: (batch_size, n_features)\n",
    "        - X_train: (n_train, n_features)\n",
    "        - Returns: (batch_size, n_train) distance matrix\n",
    "\n",
    "    Broadcasting expands X_batch to (batch_size, 1, n_features)\n",
    "    and X_train to (1, n_train, n_features), then subtracts.\n",
    "    \"\"\"\n",
    "    diff = X_batch[:, np.newaxis, :] - X_train[np.newaxis, :, :]\n",
    "    distances = np.sum(np.abs(diff), axis=2)\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Quick test with small samples\n",
    "test_distances = manhattan_distance_batch(X_test[:3], X_train[:5])\n",
    "print(f\"Distance matrix shape: {test_distances.shape}\")\n",
    "print(f\"Sample distances from test[0] to first 5 train samples:\")\n",
    "print(test_distances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1b71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Portfolio (.venv)",
   "language": "python",
   "name": "ml-portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
