{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ec9ead",
   "metadata": {},
   "source": [
    "# K-Means Clustering — No-Framework Implementation\n",
    "\n",
    "Building K-Means from scratch using only NumPy. This is the most educational implementation — we manually code every component of the algorithm.\n",
    "\n",
    "**Dataset**: Dry Beans — 13,543 samples, 16 geometric features, 7 bean types.\n",
    "\n",
    "## What We'll Build From Scratch\n",
    "- **K-Means++ initialization** — smart centroid seeding (probability ∝ distance²)\n",
    "- **Cluster assignment** — vectorized Euclidean distance via broadcasting\n",
    "- **Centroid update** — mean of assigned samples + empty cluster handling\n",
    "- **Lloyd's algorithm** — the iterative assign → update → converge loop\n",
    "- **Multi-init wrapper** — n_init runs, keep best by inertia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255b128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "K-MEANS — No-Framework\n",
      "============================================================\n",
      "Training: 10,834 samples, 16 features\n",
      "Test:     2,709 samples\n",
      "Classes:  7 (['BARBUNYA', 'BOMBAY', 'CALI', 'DERMASON', 'HOROZ', 'SEKER', 'SIRA'])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to path for utils\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from utils.data_loader import load_processed_data\n",
    "from utils.performance import track_performance\n",
    "from utils.visualization import (plot_elbow_curve, plot_silhouette_comparison,\n",
    "                                  plot_silhouette_analysis, plot_convergence_curve)\n",
    "from utils.results import save_results, add_result, print_comparison\n",
    "from utils.metrics import inertia, silhouette_score, adjusted_rand_index\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 113\n",
    "K_RANGE = range(2, 13)       # Test K=2 through K=12\n",
    "MAX_ITER = 300\n",
    "TOL = 1e-4\n",
    "N_INIT = 5                   # 5 random initializations, keep best by inertia\n",
    "FRAMEWORK = 'No-Framework'\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test, meta = load_processed_data('kmeans')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"K-MEANS — {FRAMEWORK}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test:     {X_test.shape[0]:,} samples\")\n",
    "print(f\"Classes:  {meta['n_classes']} ({meta['class_names']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d92f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids shape: (3, 16)\n",
      "First centroid: [ 0.1160314   0.49730625  0.79295167 -0.35469757  2.0429446 ]...\n",
      "Centroids are unique: True\n"
     ]
    }
   ],
   "source": [
    "# Step 1: K-Means++ initalization\n",
    "\n",
    "def kmeans_plus_plus_init(X, k, rng):\n",
    "    \"\"\"\n",
    "    Select k initial centroids using k-means++ algo.\n",
    "\n",
    "    First centroid is chosen randomly. Each subsequent centroid is \n",
    "    chosen with probability prorportional to D(x)^2 - the squared\n",
    "    distance to the nearest existing centroid. This spreads centroids\n",
    "    apart for faster, more reliable convergence.\n",
    "\n",
    "    Args:\n",
    "        X: training data (n_samples, n_featres)\n",
    "        k: Number of clusters\n",
    "        rng: np.random.Randomstate for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        centroids: initial centroid positions (k, n_features)\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    centroids = np.empty((k, n_features))\n",
    "\n",
    "    # First centroid: random data point\n",
    "    first_idx = rng.randint(0, n_samples)\n",
    "    centroids[0] = X[first_idx]\n",
    "\n",
    "    # Remaining centroids: weighted by squared distance\n",
    "    for c in range(1, k):\n",
    "        # Squared distance from each point to nearest existing centroid\n",
    "        diff = X[:, np.newaxis, :] - centroids[np.newaxis, :c, :]\n",
    "        sq_distances = np.sum(diff ** 2, axis=2)\n",
    "\n",
    "        # Distance to nearest centroid for each point\n",
    "        min_sq_dist = np.min(sq_distances, axis=1)\n",
    "\n",
    "        # Convert to probabilities\n",
    "        probs = min_sq_dist / min_sq_dist.sum()\n",
    "\n",
    "        # Choose next centroid using weighted probability\n",
    "        next_idx = rng.choice(n_samples, p=probs)\n",
    "        centroids[c] = X[next_idx]\n",
    "\n",
    "    return centroids\n",
    "\n",
    "# Quick test\n",
    "rng = np.random.RandomState(RANDOM_STATE)\n",
    "test_centroids = kmeans_plus_plus_init(X_train, k=3, rng=rng)\n",
    "print(f\"Centroids shape: {test_centroids.shape}\")\n",
    "print(f\"First centroid: {test_centroids[0][:5]}...\")\n",
    "print(f\"Centroids are unique: {len(np.unique(test_centroids, axis=0)) == 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec6c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Portfolio (.venv)",
   "language": "python",
   "name": "ml-portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
