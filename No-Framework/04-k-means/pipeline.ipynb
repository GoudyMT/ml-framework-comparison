{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ec9ead",
   "metadata": {},
   "source": [
    "# K-Means Clustering — No-Framework Implementation\n",
    "\n",
    "Building K-Means from scratch using only NumPy. This is the most educational implementation — we manually code every component of the algorithm.\n",
    "\n",
    "**Dataset**: Dry Beans — 13,543 samples, 16 geometric features, 7 bean types.\n",
    "\n",
    "## What We'll Build From Scratch\n",
    "- **K-Means++ initialization** — smart centroid seeding (probability ∝ distance²)\n",
    "- **Cluster assignment** — vectorized Euclidean distance via broadcasting\n",
    "- **Centroid update** — mean of assigned samples + empty cluster handling\n",
    "- **Lloyd's algorithm** — the iterative assign → update → converge loop\n",
    "- **Multi-init wrapper** — n_init runs, keep best by inertia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255b128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "K-MEANS — No-Framework\n",
      "============================================================\n",
      "Training: 10,834 samples, 16 features\n",
      "Test:     2,709 samples\n",
      "Classes:  7 (['BARBUNYA', 'BOMBAY', 'CALI', 'DERMASON', 'HOROZ', 'SEKER', 'SIRA'])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to path for utils\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from utils.data_loader import load_processed_data\n",
    "from utils.performance import track_performance\n",
    "from utils.visualization import (plot_elbow_curve, plot_silhouette_comparison,\n",
    "                                  plot_silhouette_analysis, plot_convergence_curve)\n",
    "from utils.results import save_results, add_result, print_comparison\n",
    "from utils.metrics import inertia, silhouette_score, adjusted_rand_index\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 113\n",
    "K_RANGE = range(2, 13)       # Test K=2 through K=12\n",
    "MAX_ITER = 300\n",
    "TOL = 1e-4\n",
    "N_INIT = 5                   # 5 random initializations, keep best by inertia\n",
    "FRAMEWORK = 'No-Framework'\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train, X_test, y_train, y_test, meta = load_processed_data('kmeans')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"K-MEANS — {FRAMEWORK}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test:     {X_test.shape[0]:,} samples\")\n",
    "print(f\"Classes:  {meta['n_classes']} ({meta['class_names']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d92f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids shape: (3, 16)\n",
      "First centroid: [ 0.1160314   0.49730625  0.79295167 -0.35469757  2.0429446 ]...\n",
      "Centroids are unique: True\n"
     ]
    }
   ],
   "source": [
    "# Step 1: K-Means++ initalization\n",
    "\n",
    "def kmeans_plus_plus_init(X, k, rng):\n",
    "    \"\"\"\n",
    "    Select k initial centroids using k-means++ algo.\n",
    "\n",
    "    First centroid is chosen randomly. Each subsequent centroid is \n",
    "    chosen with probability prorportional to D(x)^2 - the squared\n",
    "    distance to the nearest existing centroid. This spreads centroids\n",
    "    apart for faster, more reliable convergence.\n",
    "\n",
    "    Args:\n",
    "        X: training data (n_samples, n_featres)\n",
    "        k: Number of clusters\n",
    "        rng: np.random.Randomstate for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        centroids: initial centroid positions (k, n_features)\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    centroids = np.empty((k, n_features))\n",
    "\n",
    "    # First centroid: random data point\n",
    "    first_idx = rng.randint(0, n_samples)\n",
    "    centroids[0] = X[first_idx]\n",
    "\n",
    "    # Remaining centroids: weighted by squared distance\n",
    "    for c in range(1, k):\n",
    "        # Squared distance from each point to nearest existing centroid\n",
    "        diff = X[:, np.newaxis, :] - centroids[np.newaxis, :c, :]\n",
    "        sq_distances = np.sum(diff ** 2, axis=2)\n",
    "\n",
    "        # Distance to nearest centroid for each point\n",
    "        min_sq_dist = np.min(sq_distances, axis=1)\n",
    "\n",
    "        # Convert to probabilities\n",
    "        probs = min_sq_dist / min_sq_dist.sum()\n",
    "\n",
    "        # Choose next centroid using weighted probability\n",
    "        next_idx = rng.choice(n_samples, p=probs)\n",
    "        centroids[c] = X[next_idx]\n",
    "\n",
    "    return centroids\n",
    "\n",
    "# Quick test\n",
    "rng = np.random.RandomState(RANDOM_STATE)\n",
    "test_centroids = kmeans_plus_plus_init(X_train, k=3, rng=rng)\n",
    "print(f\"Centroids shape: {test_centroids.shape}\")\n",
    "print(f\"First centroid: {test_centroids[0][:5]}...\")\n",
    "print(f\"Centroids are unique: {len(np.unique(test_centroids, axis=0)) == 3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77711b",
   "metadata": {},
   "source": [
    "## Lloyd's Algorithm (Core K-Means Loop)\n",
    "\n",
    "The iterative heart of K-Means. Each iteration has two steps:\n",
    "\n",
    "1. **Assign** — For each data point, find the nearest centroid (Euclidean distance). This assigns every point to a cluster.\n",
    "2. **Update** — Recompute each centroid as the mean of all points assigned to it.\n",
    "\n",
    "Repeat until centroids stop moving (convergence) or max iterations reached.\n",
    "\n",
    "**Convergence check:** Max centroid displacement < tolerance (1e-4). If no centroid moves more than this threshold, the algorithm has stabilized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94786216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (10,)\n",
      "Labels: [0 0 0 0 0 2 0 2 2 2]\n",
      "Distances shape: (10,)\n",
      "All distances positive: True\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Assign clusters - find nearest centroid for each point\n",
    "\n",
    "def assign_clusters(X, centroids):\n",
    "    \"\"\"\n",
    "    Assign each sample to its nearest centroid using euclidean distance.\n",
    "\n",
    "    Vectorized via broadcasting:\n",
    "        X: (n_samples, n_features) -> (n_samples, 1, n_features)\n",
    "        centroids: (k, n_features) -> (1, k, n_features)\n",
    "        diff: (n_samples, k, n_features) - all pairwise differences\n",
    "    \n",
    "    Args:\n",
    "        X: data points (n_samples, n_features)\n",
    "        centroids: current centroid position (k, n_features)\n",
    "\n",
    "    Returns:\n",
    "        labels: cluster assignment for each sample (n_samples,)\n",
    "        distances: distance from each sample to  its assigned centroid (n_samples,)\n",
    "    \"\"\"\n",
    "    # Broadcasting: compute distance from every point to every centroid\n",
    "    diff = X[:, np.newaxis, :] - centroids[np.newaxis, :, :]\n",
    "    sq_distances = np.sum(diff ** 2, axis=2)    # (n_samples, k)\n",
    "\n",
    "    # Each point gets assigned to the closest centroid\n",
    "    labels = np.argmin(sq_distances, axis=1)\n",
    "\n",
    "    # distance to assigned centroid (for inertia calculation)\n",
    "    distances = sq_distances[np.arange(len(X)), labels]\n",
    "\n",
    "    return labels, distances\n",
    "\n",
    "# Quick test\n",
    "test_labels, test_dists = assign_clusters(X_train[:10], test_centroids)\n",
    "print(f\"Labels shape: {test_labels.shape}\")\n",
    "print(f\"Labels: {test_labels}\")\n",
    "print(f\"Distances shape: {test_dists.shape}\")\n",
    "print(f\"All distances positive: {np.all(test_dists >= 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeadc41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated centroids shape: (3, 16)\n",
      "No NaN values: True\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Update centroids - recompute as mean of assigned samples\n",
    "\n",
    "def update_centroids(X, labels, k, rng):\n",
    "    \"\"\"\n",
    "    Recompute each centroid as the mean of its assigned samples.\n",
    "\n",
    "    Edge case: if a cluster has no samples assigned (empty cluster),\n",
    "    reinitalize it to a random data point. This prevents NaN centroids\n",
    "    and keep all k clusters active.\n",
    "\n",
    "    Args:\n",
    "        X: data points (n_samples, n_features)\n",
    "        labels: current cluster assignemnts (n_samples,)\n",
    "        k: number of clusters\n",
    "        rng: np.random.RandomState for empty cluster reinitialization\n",
    "\n",
    "    Returns:\n",
    "        centroids: updated centroid positions (k, n_features)\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    centroids = np.empty((k, n_features))\n",
    "\n",
    "    for c in range(k):\n",
    "        mask = labels == c\n",
    "        if np.sum(mask) > 0:\n",
    "            centroids[c] = X[mask].mean(axis=0)\n",
    "        else:\n",
    "            # Empty cluster: reinitialize to random data point\n",
    "            centroids[c] = X[rng.randint(0, len(X))]\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "# Quick test\n",
    "rng = np.random.RandomState(RANDOM_STATE)\n",
    "test_updated = update_centroids(X_train[:10], test_labels, k=3, rng=rng)\n",
    "print(f\"Updated centroids shape: {test_updated.shape}\")\n",
    "print(f\"No NaN values: {not np.any(np.isnan(test_updated))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95669fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 7 iterations\n",
      "Final inertia: 75,557.90\n",
      "Inertia history length: 7\n",
      "Inertia decreased: True\n"
     ]
    }
   ],
   "source": [
    "# Step 4: single run of lloyds algorithm\n",
    "\n",
    "def kmeans_single_run(X, k, max_iter=300, tol=1e-4, rng=None):\n",
    "    \"\"\"\n",
    "    One complete run of k-means: initialize, then iterate assign/update.\n",
    "\n",
    "    Lloyds algorithm loop:\n",
    "        1. initailize centroids (k-means++)\n",
    "        2. assign each point to nearest centroid\n",
    "        3. update centroids as cluster means\n",
    "        4. check convergence: if max centroid shift < tol, stop\n",
    "        5. repeat 2-4 until converged or max_iter reached\n",
    "    \n",
    "    Args:\n",
    "        X: training data (n_samples, n_features)\n",
    "        k: number of clusters\n",
    "        max_iter: maximum iterations before stopping\n",
    "        tol: convergence threshold - max centroid displacement\n",
    "        rng: np.random.RandomState for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        centroids: final centroid positions (k, n_features)\n",
    "        labels: final cluster assignments (n_samples,)\n",
    "        final_inertia: sum of squared distances to centroids\n",
    "        n_iter: number of iterations completed\n",
    "        inertia_history: inertia at each iteration (for convergence plot)\n",
    "    \"\"\"\n",
    "    # initialize centroids using k-means++\n",
    "    centroids = kmeans_plus_plus_init(X, k, rng)\n",
    "    inertia_history = []\n",
    "\n",
    "    for iteration in range(1, max_iter + 1):\n",
    "        # assign step\n",
    "        labels, distances = assign_clusters(X, centroids)\n",
    "        current_inertia = np.sum(distances)\n",
    "        inertia_history.append(current_inertia)\n",
    "\n",
    "        # update step\n",
    "        new_centroids = update_centroids(X, labels, k, rng)\n",
    "\n",
    "        # convergence check: max centroid displacement\n",
    "        shift = np.max(np.sqrt(np.sum((new_centroids - centroids) ** 2, axis=1)))\n",
    "        centroids = new_centroids\n",
    "\n",
    "        if shift < tol:\n",
    "            break\n",
    "\n",
    "    return centroids, labels, current_inertia, iteration, inertia_history\n",
    "\n",
    "# Quick test with small k\n",
    "rng = np.random.RandomState(RANDOM_STATE)\n",
    "cents, labs, inert, n_it, hist = kmeans_single_run(X_train, k=3, rng=rng)\n",
    "print(f\"Converged in {n_it} iterations\")\n",
    "print(f\"Final inertia: {inert:,.2f}\")\n",
    "print(f\"Inertia history length: {len(hist)}\")\n",
    "print(f\"Inertia decreased: {hist[0] > hist[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc237620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Portfolio (.venv)",
   "language": "python",
   "name": "ml-portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
