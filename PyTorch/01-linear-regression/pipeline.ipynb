{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b2d89be",
   "metadata": {},
   "source": [
    "# PyTorch Linear Regression\n",
    "\n",
    "### This implementation uses PyTorch to build a linear regression model\n",
    "\n",
    "### Goal: Predict used car prices and compare with No-Framework and Scikit-Learn\n",
    "\n",
    "What PyTorch provides (That we built manually in No-Framework)\n",
    "- `torch.Tensor`: GPU-compatible arrays that track gradients automatically\n",
    "- `torch.nn.Linear`: Encapsulates weights and bias in a single layer\n",
    "- `torch.nn.MSELoss`: Pre-built loss function (replaces our manual compute_cost)\n",
    "- `torch.optim.SGD`: Optimizer that handles parameter updates (replaces manual gradient descent)\n",
    "- `auotgrad`: Automatic differentiation - computes gradients via .backward()\n",
    "\n",
    "Key Concept - Autograd:\n",
    "- In No-Framework, we manually computed gradients\n",
    "- In PyTorch, we jull call loss.backward() and gradients are computed automatically\n",
    "- This is the foundation of modern deep learning - same math, zero manual calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30b4fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "PyTorch version: 2.10.0+cpu\n",
      "Random seed set to : 113\n"
     ]
    }
   ],
   "source": [
    "# torch: The main PyTorch library for tensor operations and neural networks\n",
    "import torch\n",
    "\n",
    "# torch.nn: Neural network module containing layers, loss function, etc.\n",
    "# We import it as 'nn' for shorter syntax\n",
    "import torch.nn as nn\n",
    "\n",
    "# torch.optim: Optimization algorithms (SGD, Adam, etc.)\n",
    "# These handle the weights updates we did manually in No-Framework\n",
    "import torch.optim as optim\n",
    "\n",
    "# numpy: Still needed for initial data handling before converting to tensors\n",
    "import numpy as np\n",
    "\n",
    "#pandas: For loading CSV data\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib: for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# os: File path handling\n",
    "import os\n",
    "# Sklearn utilities: Using these for consistency with  Scikit-Learn implementation\n",
    "# This ensures identical train/test splits and scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Performance tracking\n",
    "import time\n",
    "import tracemalloc\n",
    "import platform\n",
    "\n",
    "# Set random seeds for reporducibility\n",
    "# We set seeds for BOTH numpy and torch to ensure consistent results\n",
    "RANDOM_SEED = 113\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Random seed set to : {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b112aa4",
   "metadata": {},
   "source": [
    "# Load Cleaned Data\n",
    "\n",
    "- Load the same pre-processed dataset used in NF and SL\n",
    "- Using pandas for consistency with SL implementation\n",
    "- This ensures fair comparison across all frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e9b965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100000, 12)\n",
      "Columns: ['price', 'year', 'manufacturer', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'type', 'state']\n",
      "\n",
      "First 3 rows:\n",
      "   price    year  manufacturer  condition  cylinders  fuel  odometer  \\\n",
      "0  29990  2014.0             7          2          6     2   26129.0   \n",
      "1   6995  2006.0            12          0          6     2  198947.0   \n",
      "2   4995  2009.0            35          6          8     2  152794.0   \n",
      "\n",
      "   title_status  transmission  drive  type  state  \n",
      "0             0             2      0     8     17  \n",
      "1             6             0      3    10      5  \n",
      "2             0             0      3    11     22  \n"
     ]
    }
   ],
   "source": [
    "# Define path to our cleaned dataset\n",
    "DATA_PATH = os.path.join('..', '..', 'data', 'processed', 'vehicles_clean.csv')\n",
    "\n",
    "# Load data using pandas\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Verify data loaded correctly\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68582b8",
   "metadata": {},
   "source": [
    "# Separate Features and Target\n",
    "\n",
    "- Price is our TARGET variable \n",
    "- All other columns are FEATURES\n",
    "- Same seperation as Scikit-Learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43afc6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape: (100000, 11)\n",
      "Target (y) shape: (100000,)\n",
      "\n",
      "Feature Names: ['year', 'manufacturer', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'type', 'state']\n"
     ]
    }
   ],
   "source": [
    "# Define target and column variable (same as scikit-learn)\n",
    "TARGET_COLUMN = 'price'\n",
    "FEATURE_COLUMNS = [ 'year', 'manufacturer', 'condition', 'cylinders',\n",
    "                    'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'type', 'state']\n",
    "\n",
    "# Extract target (y) and features (X) as numpy arrays\n",
    "y = df[TARGET_COLUMN].values\n",
    "X = df[FEATURE_COLUMNS].values\n",
    "\n",
    "# Store feature names for later use (displaying learned weights)\n",
    "FEATURE_NAMES = FEATURE_COLUMNS\n",
    "\n",
    "# Verify shapes \n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"\\nFeature Names: {FEATURE_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de051596",
   "metadata": {},
   "source": [
    "# Train/Test Split\n",
    "\n",
    "- Using Sklearn's train_test_split for consistency with Scikit-learn implementation\n",
    "- Same 80/20 split, same random seed (113)\n",
    "- This ensures we're comparing apples-to-applies across frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403d9dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 80,000 samples (80%)\n",
      "Test set size: 20,000 samples (20%)\n",
      "\n",
      "X_train shape: (80000, 11)\n",
      "X_test shape: (20000, 11)\n",
      "y_train shape: (80000,)\n",
      "y_test shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "# Split data using sklearn (same as Scikit-Learn)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,                          # Features to split\n",
    "    y,                          # Target to split\n",
    "    test_size=0.2,              # 20% for testing, 80% for training\n",
    "    random_state=RANDOM_SEED    # Seed 113 for reporoducibility\n",
    ")\n",
    "\n",
    "# Verify split sizes\n",
    "print(f\"Training set size: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Test set size: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a89723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Portfolio (.venv)",
   "language": "python",
   "name": "ml-portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
