{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1010d16",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) - PyTorch Implementation\n",
    "\n",
    "Multi-class classification on the **Covertype (Forest Cover Type)** dataset using PyTorch GPU acceleration.\n",
    "\n",
    "**Dataset**: 581,012 samples, 54 features, 7 forest cover types  \n",
    "**Task**: Predict forest cover type from cartographic variables  \n",
    "**Key Concept**: KNN is a \"lazy learner\" - no training phase, expensive at prediction time\n",
    "\n",
    "## PyTorch Advantages for KNN\n",
    "- **`torch.cdist`**: Highly optimized pairwise distance computation\n",
    "- **GPU acceleration**: RTX 4090 CUDA cores for parallel distance calculations\n",
    "- **Tensor operations**: Efficient top-k selection with `torch.topk`\n",
    "- **Memory management**: Batched processing to fit in 24GB VRAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb562cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4090\n",
      "VRAM: 25.8 GB\n",
      "Imports complete!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Pytorch for GPU-accelerated distance computation\n",
    "import torch\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append('../..')\n",
    "from utils.data_loader import load_processed_data\n",
    "from utils.metrics import accuracy, macro_f1_score\n",
    "from utils.visualization import (\n",
    "    plot_confusion_matrix_multiclass,\n",
    "    plot_validation_curve,\n",
    "    plot_per_class_f1\n",
    ")\n",
    "from utils.performance import track_performance\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93435c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 464,809 samples, 54 features\n",
      "Test set: 116,203 samples\n",
      "Classes (7): ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed Data\n",
    "\"\"\"\n",
    "Load the same Covertype dataset used by Scikit-Learn and No-Framework\n",
    "This ensures fair comparison across all 4 frameworks\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_test, y_train, y_test, metadata = load_processed_data('knn')\n",
    "\n",
    "# Extract metadata for reference\n",
    "class_names = metadata['class_names']\n",
    "n_classes = metadata['n_classes']\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"Classes ({n_classes}): {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1448d545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors on: cuda:0\n",
      "X_train tensor: torch.Size([464809, 54]), dtype=torch.float32\n",
      "X_test tensor:  torch.Size([116203, 54]), dtype=torch.float32\n",
      "\n",
      "GPU memory allocated: 124.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert Data to PyTorch Tensors (GPU)\n",
    "\"\"\"\n",
    "Convert NumPy arrays to PyTorch tensors and move to GPU.\n",
    "KNN requires the ENTIRE training set in memory for distance computation,\n",
    "so we load all training data onto the GPU upfront.\n",
    "\n",
    "RTX 4090 (24GB VRAM) can handle:\n",
    "    - X_train: 464,809 x 54 x 4 bytes = ~100 MB\n",
    "    - y_train: 464,809 x 4 bytes = ~2 MB\n",
    "Plenty of room for batch distance matrices during prediction\n",
    "\"\"\"\n",
    "\n",
    "# Convert to PyTorch tensors with float32 (standard for GPU computation)\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.int64, device=device)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.int64, device=device)\n",
    "\n",
    "print(f\"Tensors on: {X_train_t.device}\")\n",
    "print(f\"X_train tensor: {X_train_t.shape}, dtype={X_train_t.dtype}\")\n",
    "print(f\"X_test tensor:  {X_test_t.shape}, dtype={X_test_t.dtype}\")\n",
    "print(f\"\\nGPU memory allocated: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28c7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN prediction function defined (GPU-accelerated)\n",
      "Using: K=3, Manhattan distance (p=1), distance-weighted voting\n"
     ]
    }
   ],
   "source": [
    "# KNN Prediction Function (GPU-Accelerated)\n",
    "\"\"\"\n",
    "GPU-accelerated KNN using PyTorch's torch.cdist for distance computation.\n",
    "\n",
    "Key differences from No-Framework:\n",
    "    - torch.cdist computes pairwise distance on GPU (massively parallel)\n",
    "    - Batched prediction prevents GPU memory overflow\n",
    "    - Distance-weighted voting matches our best hyperparameters\n",
    "\n",
    "Best hyperparameters (from Scikit_learn GridSearchCV)\n",
    "    - K=3, Manhattan distance (p=1), distance-weighted voting\n",
    "\"\"\"\n",
    "\n",
    "def knn_predict_gpu(X_train, y_train, X_test, k=3, batch_size=2000, n_classes=7):\n",
    "    \"\"\"\n",
    "    GPU-accelerated KNN prediction with Manhattan distance and distance weighting.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features tensor on GPU (n_train, n_features)\n",
    "        y_train: Training labels tensor on GPU (n_train,)\n",
    "        X_test: Test features tensor on GPU (n_test, n_features)\n",
    "        k: Number of neighbors\n",
    "        batch_size: Samples per batch (tune based on VRAM)\n",
    "        n_classes: Number of classes fro voting\n",
    "\n",
    "    Returns:\n",
    "        predictions: Predicted class labels (n_test,)\n",
    "    \"\"\"\n",
    "    n_test = X_test.shape[0]\n",
    "    predictions = torch.zeros(n_test, dtype=torch.int64, device=X_test.device)\n",
    "\n",
    "    # Process test samples in batches to manage GPU memory\n",
    "    # Distance matrix per batch: (batch_size x 464,809) x 4 bytes\n",
    "    # With batch_size=2000: ~3.7 GB per batch (fits in 24GB VRAM)\n",
    "    for start_idx in range(0, n_test, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, n_test)\n",
    "        batch = X_test[start_idx:end_idx]\n",
    "\n",
    "        # Compute Manhattan (L1) distances: torch.cdist with p=1\n",
    "        # Shape: (batch_size, n_train) - distance from each test sample to all training samples\n",
    "        distances = torch.cdist(batch, X_train, p=1)\n",
    "\n",
    "        # Find k nearest neighbors (smallest distances)\n",
    "        # topk with largest=False returns smallest values\n",
    "        k_distances, k_indices = torch.topk(distances, k, largest=False)\n",
    "\n",
    "        # Get labels of K nearest neighbors\n",
    "        k_labels = y_train[k_indices] # Shape: (batch_size, k)\n",
    "\n",
    "        # Distance-weighted voting: weight = 1 / (distance + epsilon)\n",
    "        # Epsilon prevents divsion by zero for exact matches\n",
    "        epsilon = 1e-8\n",
    "        weights = 1.0 / (k_distances + epsilon) # Shape: (batch_size, k)\n",
    "\n",
    "        # Accumulate weighted votes for each class\n",
    "        # For each sample, sum weights for each class\n",
    "        batch_preds = torch.zeros(end_idx - start_idx, dtype=torch.int64, device=X_test.device)\n",
    "\n",
    "        for i in range(end_idx - start_idx):\n",
    "            class_weights = torch.zeros(n_classes, device=X_test.device)\n",
    "            for j in range(k):\n",
    "                class_idx = k_labels[i, j] - 1\n",
    "                class_weights[class_idx] += weights[i, j]\n",
    "            batch_preds[i] = torch.argmax(class_weights) + 1\n",
    "\n",
    "        predictions[start_idx:end_idx] = batch_preds\n",
    "\n",
    "    return predictions\n",
    "\n",
    "print(\"KNN prediction function defined (GPU-accelerated)\")\n",
    "print(f\"Using: K=3, Manhattan distance (p=1), distance-weighted voting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bced06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KNN prediction on test set...\n",
      "Test samples: 116,203\n",
      "Training samples: 464,809\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run KNN Prediction with Performance Tracking\n",
    "\"\"\"\n",
    "Run GPU-accelerated KNN prediction on the full test set.\n",
    "\n",
    "Note: KNN has NO training phase - all computation happens at prediction time.\n",
    "This is fundamentally different from gradient-based models like Logistic Regression.\n",
    "\"\"\"\n",
    "\n",
    "# Warm up GPU (first CUDA operation is slower due to context initialization)\n",
    "_ = torch.cdist(X_train_t[:10], X_train_t[:10], p=1)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Run prediction with performance tracking\n",
    "print(\"Running KNN prediction on test set...\")\n",
    "print(f\"Test samples: {X_test_t.shape[0]:,}\")\n",
    "print(f\"Training samples: {X_train_t.shape[0]:,}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "with track_performance() as perf:\n",
    "    y_pred_t = knn_predict_gpu(X_train_t, y_train_t, X_test_t, k=3, batch_size=2000, n_classes=n_classes)\n",
    "    torch.cuda.synchronize()  # Ensure all GPU operations complete\n",
    "\n",
    "# Convert predictions back to NumPy for metrics\n",
    "y_pred = y_pred_t.cpu().numpy()\n",
    "\n",
    "print(f\"Prediction time: {perf['time']:.2f} seconds\")\n",
    "print(f\"Peak memory: {perf['memory']:.2f} MB\")\n",
    "print(f\"Throughput: {len(X_test) / perf['time']:,.0f} samples/second\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93748234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Portfolio (.venv)",
   "language": "python",
   "name": "ml-portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
