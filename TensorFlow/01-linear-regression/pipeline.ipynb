{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8eaf69",
   "metadata": {},
   "source": [
    "# TensorFlow Linear Regression\n",
    "\n",
    "### This implementation uses TensorFlow/Keras to build a linear regression model\n",
    "\n",
    "### Goal: Predict used car prices and compare with No-Framework, Scikit-Learn, and PyTorch\n",
    "\n",
    "What TensorFlow/Keras provides (that we built manually in No-Framework):\n",
    "- `tf.keras.Sequential`: High-level API for building models layer by layer\n",
    "- `tf.keras.layers.Dense`: Fully connected layer (replaces manual weights + bias)\n",
    "- `tf.keras.losses.MeanSquaredError`: Pre-built loss function\n",
    "- `tf.keras.optimizers.SGD`: Optimizer that handles parameter updates\n",
    "- `model.fit()`: Complete training loop in one line\n",
    "\n",
    "Key Concept - Keras vs Raw TensorFlow:\n",
    "- TensorFlow 2.x uses Keras as its high-level API\n",
    "- Keras abstracts away the computational graph complexity\n",
    "- Similar to PyTorch's nn.Module, but with even simpler syntax via Sequential API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e887299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Imports successful!\n",
      "TensorFlow version: 2.20.0\n",
      "Random seed set to: 113\n"
     ]
    }
   ],
   "source": [
    "# tensorflow: The main TensorFlow Library\n",
    "import tensorflow as tf\n",
    "\n",
    "# numpy: Still needed for initial data handling\n",
    "import numpy as np\n",
    "\n",
    "# pandas: For loading CSV data\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib: for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# os: File path handling\n",
    "import os\n",
    "\n",
    "# Sklearn utilities: Using these for consistency with previous implementations\n",
    "# This ensures identical train/test splits and scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Performance tracking\n",
    "import time\n",
    "import tracemalloc\n",
    "import platform\n",
    "\n",
    "# Set random see for reproducibility\n",
    "RANDOM_SEED = 113\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"All Imports successful!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Random seed set to: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3388ce",
   "metadata": {},
   "source": [
    "# Load Cleaned Data\n",
    "\n",
    "- Load the same pre-processed dataset used in N0-Framework, Scikit-Learn, and PyTorch\n",
    "- Using pandas for consistency with SL implementation\n",
    "- This ensures fair comparison across all frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84639ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100000, 12)\n",
      "Columns: ['price', 'year', 'manufacturer', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'type', 'state']\n",
      "\n",
      "First 3 rows:\n",
      "   price    year  manufacturer  condition  cylinders  fuel  odometer  \\\n",
      "0  29990  2014.0             7          2          6     2   26129.0   \n",
      "1   6995  2006.0            12          0          6     2  198947.0   \n",
      "2   4995  2009.0            35          6          8     2  152794.0   \n",
      "\n",
      "   title_status  transmission  drive  type  state  \n",
      "0             0             2      0     8     17  \n",
      "1             6             0      3    10      5  \n",
      "2             0             0      3    11     22  \n"
     ]
    }
   ],
   "source": [
    "# Define path to our cleaned dataset\n",
    "DATA_PATH = os.path.join('..', '..', 'data', 'processed', 'vehicles_clean.csv')\n",
    "\n",
    "# Load data using pandas\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Verify data loaded correctly\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc000a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Portfolio (.venv)",
   "language": "python",
   "name": "ml-portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
