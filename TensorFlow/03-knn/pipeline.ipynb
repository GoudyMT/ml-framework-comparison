{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5143572",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) - TensorFlow Implementation\n",
    "\n",
    "Multi-class classification on the **Covertype (Forest Cover Type)** dataset using TensorFlow tensor operations.\n",
    "\n",
    "**Dataset**: 581,012 samples, 54 features, 7 forest cover types  \n",
    "**Task**: Predict forest cover type from cartographic variables  \n",
    "**Key Concept**: KNN is a \"lazy learner\" - no training phase, expensive at prediction time\n",
    "\n",
    "## TensorFlow Approach for KNN\n",
    "- **Tensor operations**: Broadcasting for pairwise distance computation\n",
    "- **`tf.math.top_k`**: Efficient K-nearest selection\n",
    "- **Batched processing**: Memory management for large datasets\n",
    "\n",
    "## Important Note: CPU-Only Execution\n",
    "- TensorFlow 2.11+ dropped native Windows GPU support. This implementation runs on CPU.\n",
    "- For GPU acceleration on Windows, options include WSL2 or TensorFlow 2.10 with Python â‰¤3.10.\n",
    "- GPU setup will be configured when we reach neural network models (DNNs, CNNs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f09b331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Running on CPU (TF 2.11+ dropped native Windows GPU support)\n",
      "Imports complete!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# TensorFlow for GPU-accelerated tensor operations\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append('../..')\n",
    "from utils.data_loader import load_processed_data\n",
    "from utils.metrics import accuracy, macro_f1_score\n",
    "from utils.visualization import (\n",
    "    plot_confusion_matrix_multiclass,\n",
    "    plot_per_class_f1\n",
    ")\n",
    "from utils.performance import track_performance\n",
    "\n",
    "# Check device\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU available: {gpus[0].name}\")\n",
    "else:\n",
    "    print(\"Running on CPU (TF 2.11+ dropped native Windows GPU support)\")\n",
    "\n",
    "print(\"Imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d79fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 464,809 samples, 54 features\n",
      "Test set: 116,203 samples\n",
      "Classes (7): ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed Data\n",
    "\"\"\"\n",
    "Load the same Covertype dataset used by Scikit-learn, No-Framework, and PyTorch.\n",
    "This ensures fair comparison across all 4 frameworks.\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_test, y_train, y_test, metadata = load_processed_data('knn')\n",
    "\n",
    "# Extract metadata for reference\n",
    "class_names = metadata['class_names']\n",
    "n_classes = metadata['n_classes']\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"Classes ({n_classes}): {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab95175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train tensor: (464809, 54), dtype=<dtype: 'float32'>\n",
      "X_test tensor:  (116203, 54), dtype=<dtype: 'float32'>\n",
      "Device: /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Convert Data to TensorFlow Tensors\n",
    "\"\"\"\n",
    "Convert NumPy arrays to TensorFlow constant tensors.\n",
    "Unlike pytorch, tensorflow tensors are immutable by default (tf.constant).\n",
    "Running on CPU since TF 2.11+ dropped native windows gpu support.\n",
    "\"\"\"\n",
    "\n",
    "# Convert to tensorflow tensors\n",
    "# tf.constant creates immutable tensors (vs pytorchs mutable torch.tensor)\n",
    "X_train_t = tf.constant(X_train, dtype=tf.float32)\n",
    "X_test_t = tf.constant(X_test, dtype=tf.float32)\n",
    "y_train_t = tf.constant(y_train, dtype=tf.int64)\n",
    "y_test_t = tf.constant(y_test, dtype=tf.int64)\n",
    "\n",
    "print(f\"X_train tensor: {X_train_t.shape}, dtype={X_train_t.dtype}\")\n",
    "print(f\"X_test tensor:  {X_test_t.shape}, dtype={X_test_t.dtype}\")\n",
    "print(f\"Device: {X_train_t.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d2c6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN prediction function defined (TensorFlow)\n",
      "Using: K=3, Manhattan distance, distance-weighted voting\n",
      "Chunked distance computation (train_chunk_size=5000, batch_size=500)\n"
     ]
    }
   ],
   "source": [
    "# KNN Prediction Function (TensorFlow)\n",
    "\"\"\"\n",
    "TensorFlow KNN using tensor operations for distance computation.\n",
    "\n",
    "Key differences from PyTorch:\n",
    "    - No tf.cdist equivalent - use broadcasting for Manhattan distance\n",
    "    - tf.math.top_k returns LARGEST by default (need to negate distances)\n",
    "    - TensorFlow tensors are immutable - different memory patterns\n",
    "    - Running on CPU (TF 2.11+ dropped native Windows GPU support)\n",
    "    - Must chunk along training axis to avoid OOM (no optimized kernel like torch.cdist)\n",
    "\n",
    "Memory consideration:\n",
    "    Broadcasting creates a 3D intermediate: (batch_size, n_train, n_features)\n",
    "    With full X_train: 500 x 464,809 x 54 x 4 bytes = ~50 GB (will crash!)\n",
    "    Chunked: 500 x 5,000 x 54 x 4 bytes = ~540 MB per chunk (manageable)\n",
    "\n",
    "Best hyperparameters (from Scikit-Learn GridSearchCV):\n",
    "    - K=3, Manhattan distance (p=1), distance-weighted voting\n",
    "\"\"\"\n",
    "\n",
    "def manhattan_distance_chunked(batch, X_train, train_chunk_size=5000):\n",
    "    \"\"\"\n",
    "    Memory-efficient manhattan distance by chunking along the training axis.\n",
    "\n",
    "    Without chunking, broadcasting creates a (batch_size, 464809, 54) tensor which requires ~50-200 GB depending on batch_size.\n",
    "    By processing X_train in chunks, peak memory stays under ~540 MB per chunk.\n",
    "\n",
    "    Args:\n",
    "        batch: test samples (batch_size, n_features)\n",
    "        X_train: training samples (n_train, n_features)\n",
    "        train_chunk_size: number of training samples per chunk\n",
    "    \n",
    "    Returns:\n",
    "        distance: (batch_size, n_train) manhattan distances\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for c_start in range(0, X_train.shape[0], train_chunk_size):\n",
    "        c_end = min(c_start + train_chunk_size, X_train.shape[0])\n",
    "        chunk = X_train[c_start:c_end]\n",
    "        # Intermediate: (batch_size, chunk_size, 54) - much smaller\n",
    "        diff = tf.abs(tf.expand_dims(batch, 1) - tf.expand_dims(chunk, 0))\n",
    "        chunks.append(tf.reduce_sum(diff, axis=2))\n",
    "    return tf.concat(chunks, axis=1)\n",
    "\n",
    "def knn_predict_tf(X_train, y_train, X_test, k=3, batch_size=500, n_classes=7):\n",
    "    \"\"\"\n",
    "    TensorFlow KNN prediction with manhattan distance and distance weighting.\n",
    "\n",
    "    Args:\n",
    "        - X_train: training features tensor (n_train, n_features)\n",
    "        - y_train: training labels tensor (n_train,)\n",
    "        - X_test: Test features tensor (n_test, n_features)\n",
    "        - k: number of neighbors\n",
    "        - batch_size: samples per batch (manages memory)\n",
    "        - n_classes: number of classes for voting\n",
    "    \n",
    "    Returns:\n",
    "        predictions: predicted class labels (n_test,)\n",
    "    \"\"\"\n",
    "    n_test = X_test.shape[0]\n",
    "    all_predictions = []\n",
    "\n",
    "    for start_idx in range(0, n_test, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, n_test)\n",
    "        batch = X_test[start_idx:end_idx]\n",
    "\n",
    "        # Compute manhattan (L1) distances using chunked approahc\n",
    "        distances = manhattan_distance_chunked(batch, X_train)\n",
    "\n",
    "        # Find k nearest neighbors\n",
    "        # tf.math.top_k returns largest values, so negate distances to get smallest\n",
    "        neg_distances = tf.negative(distances)\n",
    "        k_values, k_indices = tf.math.top_k(neg_distances, k=k)\n",
    "        k_distances = tf.negative(k_values) # Convert back to positive distances\n",
    "\n",
    "        # Get labels of K nearest neighbors\n",
    "        k_labels = tf.gather(y_train, k_indices)    # shape: (batch_size, k)\n",
    "\n",
    "        # Distance-weighted voting: weight = 1 / (distance + epsilon)\n",
    "        epsilon = 1e-8\n",
    "        weights = 1.0 / (k_distances + epsilon) # shape: (batch_size, k)\n",
    "\n",
    "        # Accumulate weighted votes for each class\n",
    "        # Labels are 1-indexed (1-7), subtract 1 for array indexing (0-6)\n",
    "        batch_preds = []\n",
    "        for i in range(end_idx - start_idx):\n",
    "            class_weights = tf.zeros(n_classes)\n",
    "            for j in range(k):\n",
    "                class_idx = k_labels[i, j] - 1 \n",
    "                # tf.tensor_scatter_nd_update to add weight at class index\n",
    "                class_weights = class_weights + tf.one_hot(class_idx, n_classes) * weights[i, j]\n",
    "            batch_preds.append(tf.argmax(class_weights) + 1)\n",
    "        \n",
    "        all_predictions.extend(batch_preds)\n",
    "    \n",
    "    return tf.cast(tf.stack(all_predictions), dtype=tf.int64)\n",
    "\n",
    "print(\"KNN prediction function defined (TensorFlow)\")\n",
    "print(f\"Using: K=3, Manhattan distance, distance-weighted voting\")\n",
    "print(f\"Chunked distance computation (train_chunk_size=5000, batch_size=500)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Portfolio (.venv)",
   "language": "python",
   "name": "ml-portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
